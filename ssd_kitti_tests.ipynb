{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "from tensorflow.contrib.slim.python.slim import queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as mpcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import dataset_factory\n",
    "from nets import nets_factory\n",
    "from preprocessing import preprocessing_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some drawing routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def colors_subselect(colors, num_classes=8):\n",
    "    dt = len(colors) // num_classes\n",
    "    sub_colors = []\n",
    "    for i in range(num_classes):\n",
    "        color = colors[i*dt]\n",
    "        if isinstance(color[0], float):\n",
    "            sub_colors.append([int(c * 255) for c in color])\n",
    "        else:\n",
    "            sub_colors.append([c for c in color])\n",
    "    return sub_colors\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"Draw a collection of lines on an image.\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def draw_rectangle(img, p1, p2, color=[255, 0, 0], thickness=2):\n",
    "    cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "    \n",
    "    \n",
    "def draw_bbox(img, bbox, shape, label, color=[255, 0, 0], thickness=2):\n",
    "    p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "    p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "    cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "    p1 = (p1[0]+15, p1[1])\n",
    "    cv2.putText(img, str(label), p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n",
    "\n",
    "\n",
    "def bboxes_draw_on_img(img, classes, scores, bboxes, colors, thickness=2):\n",
    "    shape = img.shape\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        bbox = bboxes[i]\n",
    "        color = colors[classes[i]]\n",
    "        # Draw bounding box...\n",
    "        p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "        p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "        cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "        # Draw text...\n",
    "        s = '%s/%.3f' % (classes[i], scores[i])\n",
    "        p1 = (p1[0]-5, p1[1])\n",
    "        cv2.putText(img, s, p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.4, color, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = colors_subselect(mpcm.plasma.colors, num_classes=8)##############\n",
    "colors_tableau =colors_tableau = [(255, 255, 255), (31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "                 (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "                 (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "                 (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "                 (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KITTI dataset\n",
    "\n",
    "Check the KITTI pipeline and associated TFRecords files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: /home/home/Documents/SSD/datasets/kitti_train.tfrecord | 7481\n"
     ]
    }
   ],
   "source": [
    "from datasets import kitti\n",
    "DATASET_DIR = '/home/home/Documents/SSD/datasets'\n",
    "SPLIT_NAME = 'train'\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Dataset provider loading data from the dataset.\n",
    "dataset = kitti.get_split(SPLIT_NAME, DATASET_DIR)\n",
    "provider = slim.dataset_data_provider.DatasetDataProvider(dataset, \n",
    "                                                          shuffle=False,\n",
    "                                                          common_queue_capacity=2 * BATCH_SIZE,\n",
    "                                                          common_queue_min=BATCH_SIZE)\n",
    "[image, shape, bboxes, labels] = provider.get(['image', 'shape', 'object/bbox', 'object/label'])\n",
    "print('Dataset:', dataset.data_sources, '|', dataset.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#images = tf.train.batch(\n",
    "#               [image_crop],\n",
    "#               batch_size=BATCH_SIZE,\n",
    "#                num_threads=1,\n",
    "#                capacity=5 * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem: image shape is not fully defined => random crop with deterministic size.\n",
    "xy = tf.random_uniform((2, ), minval=0, maxval=shape[0] // 3, dtype=tf.int64)\n",
    "#print(xy)\n",
    "image_crop = tf.slice(image, [0, 0, 0], [250, 250, 3])\n",
    "\n",
    "print('Original vs crop:', image.get_shape(), image_crop.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with queues.QueueRunners(sess):\n",
    "# Start populating queues.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess,coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Draw groundtruth bounding boxes using TF routine.\n",
    "image_bboxes = tf.squeeze(tf.image.draw_bounding_boxes(tf.expand_dims(tf.to_float(image) / 255., 0), \n",
    "                                                       tf.expand_dims(bboxes, 0)))\n",
    "print(image_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eval and display the image + bboxes.\n",
    "rimg, rshape, rbboxes, rlabels = sess.run([image_bboxes, shape, bboxes, labels])\n",
    "\n",
    "print('Image shape:', rimg.shape, rshape)\n",
    "print('Bounding boxes:', rbboxes)\n",
    "print('Labels:', rlabels)\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "plt.imshow(rimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SSD detector on KITTI\n",
    "\n",
    "Try out the detector on KITTI images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nets import ssd_vgg_300\n",
    "from nets import ssd_common\n",
    "from nets import np_methods\n",
    "from preprocessing import ssd_vgg_preprocessing\n",
    "\n",
    "#ckpt_filename = '/media/paul/DataExt4/PascalVOC/training/ckpts/SSD_300x300_ft/ssd_300_vgg.ckpt'\n",
    "ckpt_filename = '/home/sarah/SSD-Tensorflow/checkpoints/model.ckpt-150000'\n",
    "#ckpt_filename = '../logs/ssd_300_kitti_4/model.ckpt-2573'\n",
    "#ckpt_filename = '../logs/ssd_300_kitti_13/model.ckpt-149757'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Image pre-processimg\n",
    "out_shape = (None, None) \n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = \\\n",
    "    ssd_vgg_preprocessing.preprocess_for_eval(image, labels, bboxes, out_shape, \n",
    "                                              resize=ssd_vgg_preprocessing.Resize.NONE)\n",
    "\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# SSD construction.\n",
    "reuse = True if 'ssd' in locals() else None\n",
    "params = ssd_vgg_300.SSDNet.default_params\n",
    "params = params._replace(num_classes=8)\n",
    "ssd = ssd_vgg_300.SSDNet(params)\n",
    "with slim.arg_scope(ssd.arg_scope(weight_decay=0.0005)):\n",
    "    predictions, localisations, logits, end_points = ssd.net(image_4d, is_training=False, reuse=reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/sarah/SSD-Tensorflow/checkpoints/model.ckpt-150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/sarah/SSD-Tensorflow/checkpoints/model.ckpt-150000\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "# Restore SSD model.\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, ckpt_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run model and get predictions.\n",
    "[rimg, rpredictions, rlocalisations, glabels, gbboxes, rbbox_img] = \\\n",
    "    sess.run([image_4d, predictions, localisations, labels, bboxes_pre, bbox_img])\n",
    "rimg = rimg[0]\n",
    "\n",
    "# Update anchor boxes to image size.\n",
    "ssd.update_feature_shapes(rpredictions)\n",
    "anchors = ssd.anchors(rimg.shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute classes and bboxes from the net outputs.\n",
    "rclasses, rscores, rbboxes= np_methods.ssd_bboxes_select(rpredictions, rlocalisations, anchors,\n",
    "                                                               select_threshold=0.8, img_shape=rimg.shape, \n",
    "                                                               num_classes=8, decode=True)\n",
    "rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n",
    "rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes,nms_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Draw bboxes\n",
    "img_bboxes = np.copy(ssd_vgg_preprocessing.np_image_unwhitened(rimg))\n",
    "bboxes_draw_on_img(img_bboxes, rclasses, rscores, rbboxes, colors_tableau, thickness=1)\n",
    "# bboxes_draw_on_img(img_bboxes, test_labels, test_scores, test_bboxes, colors_tableau, thickness=1)\n",
    "\n",
    "print('Labels / scores:', list(zip(rclasses, rscores)))\n",
    "print('Grountruth labels:', list(glabels))\n",
    "print(gbboxes)\n",
    "\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "plt.imshow(img_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "~isinstance(rpredictions[0], np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tanh_weighted(x, w=[1., 1.]):\n",
    "    r = (w[0]*np.exp(x) - w[1]*np.exp(-x)) / (w[0]*np.exp(x) + w[1]*np.exp(-x))\n",
    "    return r\n",
    "\n",
    "x = np.arange(0, 1, 0.01)\n",
    "y = (tanh_weighted((x - 0.5) * 8, [1, 1]) + 1) / 2.\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SSD-300 model using TFRecords pipeline\n",
    "\n",
    "Restore model and test it on some random images coming from Pascal TFRecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nets import ssd_vgg_300\n",
    "from nets import ssd_common\n",
    "from nets import np_methods\n",
    "from preprocessing import ssd_vgg_preprocessing\n",
    "\n",
    "\n",
    "ckpt_filename = './checkpoints/model.ckpt-150000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Image pre-processimg\n",
    "out_shape = (300, 300) \n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = \\\n",
    "    ssd_vgg_preprocessing.preprocess_for_eval(image, labels, bboxes, out_shape, \n",
    "                                          resize=ssd_vgg_preprocessing.Resize.PAD_AND_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# SSD construction.\n",
    "reuse = True if 'ssd' in locals() else None\n",
    "params = ssd_vgg_300.SSDNet.default_params\n",
    "ssd = ssd_vgg_300.SSDNet(params)\n",
    "with slim.arg_scope(ssd.arg_scope(weight_decay=0.0005)):\n",
    "    predictions, localisations, logits, end_points = ssd.net(image_4d, is_training=False, reuse=reuse)\n",
    "    \n",
    "# SSD default anchor boxes.\n",
    "img_shape = out_shape\n",
    "layers_anchors = ssd.anchors(img_shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Targets encoding.\n",
    "target_labels, target_localizations, target_scores = ssd_common.tf_ssd_bboxes_encode(labels, bboxes_pre, layers_anchors,8,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "# Restore SSD model.\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, ckpt_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run model.\n",
    "[rimg, rpredictions, rlocalisations, glabels, gbboxes, rbbox_img, rt_labels, rt_localizations, rt_scores] = \\\n",
    "    sess.run([image_4d, predictions, localisations, labels, bboxes_pre, bbox_img, \n",
    "               target_labels, target_localizations, target_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute classes and bboxes from the net outputs.\n",
    "rclasses, rscores, rbboxes,_,_ = ssd_common.ssd_bboxes_select(rpredictions, rlocalisations, layers_anchors,\n",
    "                                                               threshold=0.5, img_shape=img_shape, \n",
    "                                                               num_classes=8, decode=True)\n",
    "rbboxes = ssd_common.bboxes_clip(rbbox_img, rbboxes)\n",
    "rclasses, rscores, rbboxes = ssd_common.bboxes_sort(rclasses, rscores, rbboxes, top_k=400, priority_inside=False)\n",
    "rclasses, rscores, rbboxes = ssd_common.bboxes_nms(rclasses, rscores, rbboxes, threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw bboxes\n",
    "img_bboxes = np.copy(ssd_preprocessing.np_image_unwhitened(rimg[0]))\n",
    "bboxes_draw_on_img(img_bboxes, rclasses, rscores, rbboxes, colors_tableau, thickness=1)\n",
    "# bboxes_draw_on_img(img_bboxes, test_labels, test_scores, test_bboxes, colors_tableau, thickness=1)\n",
    "\n",
    "print('Labels / scores:', list(zip(rclasses, rscores)))\n",
    "print('Grountruth labels:', list(glabels))\n",
    "print(gbboxes)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "plt.imshow(img_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bboxes = []\n",
    "test_labels = []\n",
    "test_scores = []\n",
    "for i in range(0, 3):\n",
    "    yref, xref, href, wref = layers_anchors[i]\n",
    "    ymin = yref - href / 2.\n",
    "    xmin = xref - wref / 2.\n",
    "    ymax = yref + href / 2.\n",
    "    xmax = xref + wref / 2.\n",
    "    bb = np.stack([ymin, xmin, ymax, xmax], axis=-1)\n",
    "    \n",
    "    idx = yref.shape[0] // 2\n",
    "    idx = np.random.randint(yref.shape[0])\n",
    "#     print(bb[idx, idx].shape)\n",
    "    test_bboxes.append(bb[idx, idx])\n",
    "    test_labels.append(np.ones(href.shape, dtype=np.int64) * i)\n",
    "    test_scores.append(np.ones(href.shape))\n",
    "\n",
    "test_bboxes = np.concatenate(test_bboxes)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "test_scores = np.concatenate(test_scores)\n",
    "\n",
    "print(test_bboxes.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_scores.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_labels, rt_localizations, rt_scores\n",
    "for i in range(len(rt_labels)):\n",
    "    print(rt_labels[i].shape)\n",
    "    idxes = np.where(rt_labels[i] > 0)\n",
    "#     idxes = np.where(rt_scores[i] > 0.)\n",
    "    print(idxes)\n",
    "    print(rt_localizations[i][idxes])\n",
    "    print(list(zip(rt_labels[i][idxes], rt_scores[i][idxes])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (8,8))\n",
    "# plt.imshow(ssd_preprocessing.np_image_unwhitened(rimg[0]))\n",
    "# print('Ground truth labels: ', rlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Request threads to stop. Just to avoid error messages\n",
    "# coord.request_stop()\n",
    "# coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PleaseStopHere;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SSD-300 model using sample images\n",
    "\n",
    "Restore model and test it on some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input placeholder.\n",
    "net_shape = (300, 300)\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n",
    "    img_input, labels, None, net_shape, resize=ssd_vgg_preprocessing.Resize.PAD_AND_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Re-define the model\n",
    "reuse = True if 'ssd' in locals() else None\n",
    "with slim.arg_scope(ssd.arg_scope(weight_decay=0.0005)):\n",
    "    predictions, localisations, logits, end_points = ssd.net(image_4d, is_training=False, reuse=reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main processing routine.\n",
    "def process_image(img, select_threshold=0.5, nms_threshold=0.35, net_shape=(300, 300)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = sess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    # Compute classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes, rlayers, ridxes = ssd_common.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, layers_anchors,\n",
    "            threshold=select_threshold, img_shape=net_shape, num_classes=21, decode=True)\n",
    "#     print(list(zip(classes, scores)))\n",
    "#     print(rlayers)\n",
    "#     print(ridxes)\n",
    "    \n",
    "    rbboxes = ssd_common.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = ssd_common.bboxes_sort(rclasses, rscores, rbboxes, \n",
    "                                                        top_k=400, priority_inside=True, margin=0.0)\n",
    "    rclasses, rscores, rbboxes = ssd_common.bboxes_nms(rclasses, rscores, rbboxes, threshold=nms_threshold)\n",
    "    # Resize bboxes to original image shape.\n",
    "    rbboxes = ssd_common.bboxes_resize(rbbox_img, rbboxes)\n",
    "    return rclasses, rscores, rbboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test on demo images.\n",
    "path = 'demo/'\n",
    "image_names = sorted(os.listdir(path))\n",
    "img = mpimg.imread(path + image_names[3])\n",
    "\n",
    "rclasses, rscores, rbboxes =  process_image(img)\n",
    "\n",
    "# Draw results.\n",
    "img_bboxes = np.copy(img)\n",
    "bboxes_draw_on_img(img_bboxes, rclasses, rscores, rbboxes, colors_tableau, thickness=2)\n",
    "\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "plt.imshow(img_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxes = np.where(inside)\n",
    "rscores[idxes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some TensorFlow tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[5.0, 2], [5.0, 2]])\n",
    "b = tf.constant([5.0, 2])\n",
    "c = a * b\n",
    "d = tf.nn.l2_normalize(a, dim=1)\n",
    "# We can just use 'c.eval()' without passing 'sess'\n",
    "print(d.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few tests on Caffe model files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import numpy as np\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "caffe_filename = '/media/paul/DataExt4/PascalVOC/training/ckpts/SSD_300x300_ft/ssd_300_vgg.caffemodel'\n",
    "caffemodel_params = caffe_pb2.NetParameter()\n",
    "caffemodel_str = open(caffe_filename, 'rb').read()\n",
    "caffemodel_params.ParseFromString(caffemodel_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = caffemodel_params.layer\n",
    "names = [(i, l.name) for i, l in enumerate(layers)]\n",
    "types = set([l.type for i, l in enumerate(layers)])\n",
    "print(types)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = layers[59]\n",
    "layer = layers[1]\n",
    "print(layer.type)\n",
    "a = np.array(layer.blobs[0].data)\n",
    "s = layer.blobs[0].shape\n",
    "print(s, 38*38)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nets import caffe_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csc = caffe_scope.CaffeScope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "d[csc.conv_biases_init] = 0\n",
    "d[csc.conv_biases_init] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_dim = 300\n",
    "mbox_source_layers = ['conv4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'conv9_2']\n",
    "min_ratio = 15\n",
    "max_ratio = 90\n",
    "step = int(math.floor((max_ratio - min_ratio) / (len(mbox_source_layers) - 2)))\n",
    "min_sizes = []\n",
    "max_sizes = []\n",
    "for ratio in range(min_ratio, max_ratio + 1, step):\n",
    "    min_sizes.append(min_dim * ratio / 100.)\n",
    "    max_sizes.append(min_dim * (ratio + step) / 100.)\n",
    "min_sizes = [min_dim * 7 / 100.] + min_sizes\n",
    "max_sizes = [min_dim * 15 / 100.] + max_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(min_sizes)\n",
    "print(max_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_shapes=[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [8, 16, 32, 64, 100, 300]\n",
    "offset = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(steps)):\n",
    "    print((feat_shapes[i][0] - offset) * steps[i] / 300, (feat_shapes[i][0] - offset) / feat_shapes[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "37.5 * 8. / 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".5 / 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "~True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
